{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACS_variables.csv', 'Additional_DataAlabama.csv', 'Additional_DataAlaska.csv', 'Additional_DataArizona.csv', 'Additional_DataArkansas.csv']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-facb05c72a46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0maddl_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Additional'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maddl_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# measure_data =\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "# combine all state files instead of just a single state\n",
    "# read_state = 'Ohio'\n",
    "\n",
    "files = os.listdir('../input/')\n",
    "print(files[:5])\n",
    "\n",
    "np.where('Additional' in files)\n",
    "\n",
    "addl_index = ['Additional' in filename for filename in files]\n",
    "# files.iloc[addl_index]\n",
    "\n",
    "# measure_data =\n",
    "# addtl_data =\n",
    "# output these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   FIPS  State   County  Years of Potential Life Lost Rate  \\\n",
      "0  0   FIPS  State   County  Years of Potential Life Lost Rate   \n",
      "1  1  39000   Ohio      NaN                       8491.5605314   \n",
      "2  2  39001   Ohio    Adams                       12469.382097   \n",
      "3  3  39003   Ohio    Allen                       9033.4799458   \n",
      "4  4  39005   Ohio  Ashland                       7305.2843493   \n",
      "\n",
      "  % Long Commute - Drives Alone_95% CI - Low  \\\n",
      "0                               95% CI - Low   \n",
      "1                                8429.924233   \n",
      "2                               10903.355914   \n",
      "3                               8355.2480965   \n",
      "4                                6446.080331   \n",
      "\n",
      "  % Long Commute - Drives Alone_95% CI - High  \\\n",
      "0                               95% CI - High   \n",
      "1                                8553.1968299   \n",
      "2                                14035.408279   \n",
      "3                                9711.7117951   \n",
      "4                                8164.4883677   \n",
      "\n",
      "  % Long Commute - Drives Alone_Z-Score  YPLL Rate (Black)  \\\n",
      "0                               Z-Score  YPLL Rate (Black)   \n",
      "1                                   NaN                NaN   \n",
      "2                          2.2428773971                NaN   \n",
      "3                           0.294005764       13089.069915   \n",
      "4                          -0.686240828                NaN   \n",
      "\n",
      "   YPLL Rate (Hispanic)  ... % Long Commute - Drives Alone_95% CI - High  \\\n",
      "0  YPLL Rate (Hispanic)  ...                               95% CI - High   \n",
      "1                   NaN  ...                                83.581428713   \n",
      "2                   NaN  ...                                85.047473101   \n",
      "3                   NaN  ...                                87.783534549   \n",
      "4                   NaN  ...                                86.821261991   \n",
      "\n",
      "  % Long Commute - Drives Alone_Z-Score  % Drive Alone (Black)  \\\n",
      "0                               Z-Score  % Drive Alone (Black)   \n",
      "1                                   NaN                    NaN   \n",
      "2                          -0.758812694                    NaN   \n",
      "3                          0.5132940904           78.202531646   \n",
      "4                          0.1726703488                    NaN   \n",
      "\n",
      "   % Drive Alone (Hispanic)  % Drive Alone (White)  # Workers who Drive Alone  \\\n",
      "0  % Drive Alone (Hispanic)  % Drive Alone (White)  # Workers who Drive Alone   \n",
      "1                       NaN                    NaN                    4490622   \n",
      "2                       NaN                    NaN                       8069   \n",
      "3               81.64652568           88.231296851                      40907   \n",
      "4                       NaN                    NaN                      20724   \n",
      "\n",
      "   % Long Commute - Drives Alone % Long Commute - Drives Alone_95% CI - Low  \\\n",
      "0  % Long Commute - Drives Alone                               95% CI - Low   \n",
      "1                           30.3                               30.061702128   \n",
      "2                           50.1                               43.685846343   \n",
      "3                             17                               15.560317927   \n",
      "4                           32.5                                 29.5960884   \n",
      "\n",
      "  % Long Commute - Drives Alone_95% CI - High  \\\n",
      "0                               95% CI - High   \n",
      "1                                30.538297872   \n",
      "2                                56.514153657   \n",
      "3                                18.439682073   \n",
      "4                                  35.4039116   \n",
      "\n",
      "  % Long Commute - Drives Alone_Z-Score  \n",
      "0                               Z-Score  \n",
      "1                                   NaN  \n",
      "2                          1.7869077442  \n",
      "3                          -1.645727537  \n",
      "4                           -0.03830014  \n",
      "\n",
      "[5 rows x 163 columns]\n"
     ]
    }
   ],
   "source": [
    "measure_data = pd.read_csv(f'../input/Measure_Data_{read_state}.csv')\n",
    "\n",
    "def replace_column_names(df):\n",
    "    colnames = df.head(1).values\n",
    "    # print(list(colnames))\n",
    "    # colnames = colnames.tolist()\n",
    "    colnames = list(colnames)[0]\n",
    "    df.columns = colnames\n",
    "\n",
    "    # drop the first row that contains the column names\n",
    "    # measure_data.loc[0]\n",
    "    # measure_data.loc[-1,:]\n",
    "    # print(measure_data.head())\n",
    "    return df\n",
    "\n",
    "measure_data = replace_column_names(measure_data)\n",
    "\n",
    "def concatenate_column_names(col):\n",
    "    if col in [0,'FIPS','State','County']:\n",
    "        return col\n",
    "    else:\n",
    "        if col not in ['95% CI - Low','95% CI - High','Z-Score']:\n",
    "            return col\n",
    "        else:\n",
    "            return metric + \"_\" + col\n",
    "\n",
    "col_num = 0\n",
    "for col in measure_data.columns.values:\n",
    "    measure_data.columns.values[col_num] = concatenate_column_names(col)\n",
    "    col_num += 1\n",
    "    \n",
    "print(measure_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   FIPS  State   County  Life Expectancy  \\\n",
      "0  0   FIPS  State   County  Life Expectancy   \n",
      "1  1  39000   Ohio      NaN     77.018253398   \n",
      "2  2  39001   Ohio    Adams     72.956033247   \n",
      "3  3  39003   Ohio    Allen     76.585681073   \n",
      "4  4  39005   Ohio  Ashland     78.036945142   \n",
      "\n",
      "  % Long Commute - Drives Alone_95% CI - Low  \\\n",
      "0                               95% CI - Low   \n",
      "1                               76.965026091   \n",
      "2                               71.818677339   \n",
      "3                                76.01166123   \n",
      "4                               77.279574885   \n",
      "\n",
      "  % Long Commute - Drives Alone_95% CI - High  Life Expectancy (Black)  \\\n",
      "0                               95% CI - High  Life Expectancy (Black)   \n",
      "1                                77.071480706                      NaN   \n",
      "2                                74.093389155                      NaN   \n",
      "3                                77.159700915             72.959790641   \n",
      "4                                  78.7943154                      NaN   \n",
      "\n",
      "   Life Expectancy (Hispanic)  Life Expectancy (White)  ...    % Hispanic  \\\n",
      "0  Life Expectancy (Hispanic)  Life Expectancy (White)  ...    % Hispanic   \n",
      "1                         NaN                      NaN  ...  3.7816346701   \n",
      "2                         NaN                      NaN  ...  0.9954555291   \n",
      "3                102.33052212             77.032720727  ...  3.0921141883   \n",
      "4                         NaN                      NaN  ...  1.3891996718   \n",
      "\n",
      "   # Non-Hispanic White  % Non-Hispanic White  # Not Proficient in English  \\\n",
      "0  # Non-Hispanic White  % Non-Hispanic White  # Not Proficient in English   \n",
      "1               9219577          79.079562579                       111447   \n",
      "2                 26748          96.472624973                            9   \n",
      "3                 83384          80.800015504                          395   \n",
      "4                 51347          95.746624897                          532   \n",
      "\n",
      "   % Not Proficient in English % Long Commute - Drives Alone_95% CI - Low  \\\n",
      "0  % Not Proficient in English                               95% CI - Low   \n",
      "1                 1.0211331227                               0.9875352457   \n",
      "2                 0.0343419697                                          0   \n",
      "3                 0.4042988741                               0.1861858609   \n",
      "4                 1.0608387007                               0.3893014755   \n",
      "\n",
      "  % Long Commute - Drives Alone_95% CI - High      % Female  # Rural  \\\n",
      "0                               95% CI - High      % Female  # Rural   \n",
      "1                                1.0547309997  50.996726968  2546810   \n",
      "2                                0.4112043798  50.241650436    25417   \n",
      "3                                0.6224118873   49.51937053    27530   \n",
      "4                                1.7323759258  50.949131051    32913   \n",
      "\n",
      "        % Rural  \n",
      "0       % Rural  \n",
      "1  22.076098617  \n",
      "2  89.026269702  \n",
      "3  25.890850269  \n",
      "4  61.937559984  \n",
      "\n",
      "[5 rows x 112 columns]\n"
     ]
    }
   ],
   "source": [
    "addtl_data = pd.read_csv(f'../input/Additional_Data{read_state}.csv')\n",
    "addtl_data = replace_column_names(addtl_data)\n",
    "\n",
    "col_num = 0\n",
    "for col in addtl_data.columns.values:\n",
    "    addtl_data.columns.values[col_num] = concatenate_column_names(col)\n",
    "    col_num += 1\n",
    "print(addtl_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine measure data with additional data\n",
    "rwjf_data = pd.merge(measure_data, addtl_data, on = ['FIPS','State','County'])\n",
    "assert((measure_data.shape[0]) == (addtl_data.shape[0]) == (rwjf_data.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AHRQ-ebGvUS5S",
   "language": "python",
   "name": "ahrq-ebgvus5s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
